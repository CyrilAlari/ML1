{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import hmean\n",
    "\n",
    "import gini\n",
    "from util_data import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_encode(trn_series,    \n",
    "                  tst_series,\n",
    "                  target,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1):\n",
    "\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    \n",
    "    return ft_trn_series, ft_tst_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlated_features = [\"ps_reg_03\",\"ps_car_13\"]\n",
    "lacunar_features = [\"ps_car_03_cat\",\"ps_car_05_cat\"]\n",
    "combination_features = ['ps_reg_01', 'ps_car_02_cat', 'ps_car_04_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = DataSet()\n",
    "\n",
    "train = data.get_training_set()\n",
    "test = data.get_testing_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]\n",
    "\n",
    "for f1, f2 in combs:\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    train[name1] = train[f1].apply(lambda x: str(x)) + \"_\" + train[f2].apply(lambda x: str(x))\n",
    "    test[name1] = test[f1].apply(lambda x: str(x)) + \"_\" + test[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train[name1].values) + list(test[name1].values))\n",
    "    train[name1] = lbl.transform(list(train[name1].values))\n",
    "    test[name1] = lbl.transform(list(test[name1].values))\n",
    "    train_features.append(name1)\n",
    "\n",
    "    \n",
    "categorical_features = (train.filter(like='cat')).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "LEARNING_RATE = 0.07\n",
    "\n",
    "rfc = XGBClassifier(    \n",
    "                        n_estimators=MAX_ROUNDS,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=LEARNING_RATE, \n",
    "                        subsample=.8,\n",
    "                        min_child_weight=6,\n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight=1.6,\n",
    "                        gamma=10,\n",
    "                        reg_alpha=8,\n",
    "                        reg_lambda=1.3,\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = KFold(25, shuffle = True)\n",
    "ginis = []\n",
    "train = train.drop(X.filter(like='calc').columns,axis=1).drop(correlated_features,axis=1).drop(lacunar_features,axis=1)\n",
    "train = test.drop(X.filter(like='calc').columns,axis=1).drop(correlated_features,axis=1).drop(lacunar_features,axis=1)\n",
    "\n",
    "categorical_features = (train.filter(like='cat')).columns\n",
    "ones = train[train[\"target\"]==1].index.values\n",
    "zeros = train[train[\"target\"]==0].index.values\n",
    "\n",
    "X_train, X_test, Y_train = train.drop([\"id\",\"target\"],axis=1),test.drop([\"id\"],axis=1),train.target\n",
    "\n",
    "split = fd.split(X_train.iloc[zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.145, Max. Gini: 0.482, Normalized Gini: 0.301\n",
      "Gini: 0.151, Max. Gini: 0.482, Normalized Gini: 0.313\n",
      "Gini: 0.148, Max. Gini: 0.481, Normalized Gini: 0.307\n",
      "Gini: 0.147, Max. Gini: 0.482, Normalized Gini: 0.304\n",
      "Gini: 0.148, Max. Gini: 0.482, Normalized Gini: 0.307\n"
     ]
    }
   ],
   "source": [
    "Y_preds = np.zeros((X_test.shape[0],5))\n",
    "\n",
    "for i,(tr_i, tst_i) in enumerate(split):\n",
    "    local_train = X_train.iloc[np.concatenate([tr_i,ones]),:][train_features].copy()\n",
    "    local_test = X_test[train_features].copy()\n",
    "    \n",
    "    for f in categorical_features:\n",
    "        local_train[f + \"_avg\"],local_val[f + \"_avg\"],local_test[f + \"_avg\"] = target_encode(\n",
    "                                                            trn_series=local_train[f],\n",
    "                                                            tst_series=local_test[f],\n",
    "                                                            target=Y_train[np.concatenate([tr_i,ones])],\n",
    "                                                            min_samples_leaf=200,\n",
    "                                                            smoothing=10,\n",
    "                                                            )\n",
    "        local_train.drop(f,axis=1)\n",
    "        local_test.drop(f,axis=1)\n",
    "\n",
    "    \n",
    "    fitrfc = rfc.fit(local_train,Y_train[np.concatenate([tr_i,ones])])\n",
    "    \n",
    "    # We make prediction\n",
    "    Y_preds[:,i] = fitrfc.predict_proba(local_test)[:,1]\n",
    "    \n",
    "    del local_train, local_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "k=0\n",
    "total = sum(1 for i in ginis)\n",
    "for i in test.id:\n",
    "    res.append([i,np.mean(Y_preds[k,:])])\n",
    "    k+=1\n",
    "\n",
    "pd.DataFrame(res,columns=[\"id\",\"target\"]).to_csv(\"prednorm.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
