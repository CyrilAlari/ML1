{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment (data + libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "train = pd.read_csv('data/training_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skimming through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to extract some data instances\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the sample of 5 extracted rows:\n",
    "* 46 features\n",
    "* NULL values are denoted as NaN (and not -1 as in Porto Segure competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns.values # all the features of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above summary:\n",
    "* total rows: **992,931**\n",
    "* types of features:\n",
    "    * **categorical**: city, bd, gender, registered_via, is_auto_renew_median, is_auto_renew_last, plan_list_price_mean, plan_list_price_last, is_cancel_mean, is_cancel_last\n",
    "    * **object**: TimeSinceReg, msno\n",
    "    * **numerical**: all the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['msno','is_churn']].groupby(['is_churn'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'0' denotes clients who renews their service and '1' those who churn. Approximately, only **6.82%** of customers churn after the expiration of their subscription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (by human understanding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers the process of feature selection but only based on human understanding i.e. which features deemed reasonable to be removed manually, without considering any indicator of feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train['is_churn'] # extract the label variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features to remove\n",
    "to_rem = ['Unnamed: 0', 'msno', 'is_churn', 'membership_expire_date_last', 'transaction_date_last']\n",
    "\n",
    "# please correct me if I'm wrong but I don't think records about transaction date would have important effect on the prediction, \n",
    "# except the one of TimeSinceReg\n",
    "X = train.drop(to_rem, axis=1) # remove no., msno, is_churn from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature transformation (TimeSinceReg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the number of days from the attribute TimeSinceReg\n",
    "# at first the data was '4000 days 00:00:00.000000...'\n",
    "# at the end, we only need the concrete day such as 4000 --> replace the original data of TimeSinceReg by the number of days\n",
    "\n",
    "regexp = re.compile('(-?[0-9]+)')\n",
    "tmp = []\n",
    "for t in train['TimeSinceReg']:\n",
    "    if type(t) is not str:\n",
    "        tmp.append(0)\n",
    "        continue\n",
    "    result = regexp.match(t)\n",
    "    tmp.append(int(result.group(0)))\n",
    "\n",
    "X['TimeSinceReg'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step, all data of ambiguous type *object* (msno and TimeSinceRef) have been either removed or transformed into another type appropriate for machine learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lacunar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().any(axis=1).sum() # count the total number of rows that have one or more null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 296 529 rows that have null values on one or more attributes. Approximately, these rows occupy **29.86%** over the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the list of all categorical features\n",
    "cat_feat = [\n",
    "    \"city\",\n",
    "    \"bd\",\n",
    "    \"gender\", \n",
    "    'registered_via', \n",
    "    'is_auto_renew_median', \n",
    "    'is_auto_renew_last',\n",
    "    'plan_list_price_mean', \n",
    "    'plan_list_price_last',\n",
    "    'is_cancel_mean','is_cancel_last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_num = X.drop(cat_feat, axis=1) # extract the training set that contains only numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# libraries to do pretty plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seaborn style\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting correlation matrix\n",
    "cor_matrix = X_num.corr().round(2)\n",
    "\n",
    "# Plotting heatmap \n",
    "fig = plt.figure(figsize=(20,20));\n",
    "sns.heatmap(cor_matrix, annot=True, center=0, cmap = sns.diverging_palette(250, 10, as_cmap=True), ax=plt.subplot(111));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlated features can be easily deduced from this correlation matrix. Said features are listed as follows (threshold >= 0.8):\n",
    "* payment_plan_days_mean <==> payment_plan_days_last, actual_amound_paid_mean, actual_amount_paid_last\n",
    "* payment_method_id_mean <==> payment_method_id_last\n",
    "* num_25_avg_1mo <==> num_25_avg_3mo\n",
    "* num_50_avg_1mo <==> num_50_avg_3mo\n",
    "* num_75_avg_1mo <==> num_75_avg_3mo\n",
    "* num_985_avg_1mo <==> num_985_avg_3mo\n",
    "* num_100_avg_1mo <==> num_100_avg_3mo (there is an interesting pattern between those **1mo** and **3mo**), total_secs_avg_1mo, total_secs_avg_3mo\n",
    "* num_unq_avg_1mo <==> total_secs_avg_1mo, num_unq_avg_3mo\n",
    "* count_1mo <==> count_3mo\n",
    "* num_100_avg_3mo <==> total_secs_avg_3mo\n",
    "* num_unq_avg_3mo <==> num_unq_avg_6mo\n",
    "* total_secs_avg_3mo <==> total_secs_avg_6mo\n",
    "* num_100_avg_6mo <==> num_unq_avg_6mo, total_secs_avg_6mo\n",
    "* num_unq_avg_6mo <==> total_secs_avg_6mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the number of distinct values for categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in cat_feat:\n",
    "    print('%s has %d unique values' % (v, len(X[v].unique())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
