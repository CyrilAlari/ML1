{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import hmean\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from util_data import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_encode(trn_series,    \n",
    "                  tst_series,\n",
    "                  target,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1):\n",
    "\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    \n",
    "    return ft_trn_series, ft_tst_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlated_features = [\"membership_expire_date_last\",\"transaction_date_last\"]\n",
    "lacunar_features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = DataSet()\n",
    "\n",
    "train = data.get_training_set()\n",
    "test = data.get_testing_set()\n",
    "\n",
    "categorical_features = [\"city\",\"bd\",\"gender\", 'registered_via', 'is_auto_renew_median', 'is_auto_renew_last','plan_list_price_mean', 'plan_list_price_last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combs = [\n",
    "]\n",
    "\n",
    "for f1, f2 in combs:\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    train[name1] = train[f1].apply(lambda x: str(x)) + \"_\" + train[f2].apply(lambda x: str(x))\n",
    "    test[name1] = test[f1].apply(lambda x: str(x)) + \"_\" + test[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train[name1].values) + list(test[name1].values))\n",
    "    train[name1] = lbl.transform(list(train[name1].values))\n",
    "    test[name1] = lbl.transform(list(test[name1].values))\n",
    "    train_features.append(name1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "LEARNING_RATE = 0.07\n",
    "\n",
    "rfc = XGBClassifier(    \n",
    "        learning_rate=0.02, #use 0.002\n",
    "        max_depth= 7,\n",
    "        objective= 'binary:logistic',\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(correlated_features,axis=1).drop(lacunar_features,axis=1)\n",
    "test = test.drop(correlated_features,axis=1).drop(lacunar_features,axis=1)\n",
    "\n",
    "train[\"TimeSinceReg\"] = train[\"TimeSinceReg\"].replace(\"nan\",\"0\")\n",
    "test[\"TimeSinceReg\"] = test[\"TimeSinceReg\"].replace(\"nan\",\"0\")\n",
    "\n",
    "train[\"TimeSinceReg\"] = train[\"TimeSinceReg\"].apply(lambda chaine : int(chaine.split(\" \")[0]))\n",
    "test[\"TimeSinceReg\"] = test[\"TimeSinceReg\"].apply(lambda chaine : int(chaine.split(\" \")[0]))\n",
    "\n",
    "#train.columns = train.columns.sort_values()\n",
    "#test.columns = test.columns.sort_values()\n",
    "test= test.drop([\"date_avg_6mo\", \"date_avg_1mo\"],axis=1)\n",
    "\n",
    "cols = train.columns.tolist()\n",
    "cols.remove(\"is_churn\")\n",
    "test = test[cols]\n",
    "\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "\n",
    "X_train, X_test, Y_train = train.drop([\"msno\",\"is_churn\"],axis=1),test.drop([\"msno\"],axis=1),train.is_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-69-a7f7109b4b97>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-69-a7f7109b4b97>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    Y_preds = fitrfc.predict_proba(local_test,axis=1))[:,1]\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Y_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "local_train = X_train\n",
    "local_test = X_test\n",
    "    \n",
    "for f in tqdm_notebook(categorical_features):\n",
    "    local_train[f + \"_avg\"],local_test[f + \"_avg\"] = target_encode(\n",
    "                                                            trn_series=local_train[f],\n",
    "                                                            tst_series=local_test[f],\n",
    "                                                            target=Y_train,\n",
    "                                                            min_samples_leaf=200,\n",
    "                                                            smoothing=10,\n",
    "                                                            )\n",
    "local_train = local_train.drop(categorical_features,axis=1)\n",
    "local_test = local_test.drop(categorical_features,axis=1)\n",
    "\n",
    "    \n",
    "fitrfc = rfc.fit(local_train,Y_train,verbose=True)\n",
    "Y_preds = fitrfc.predict_proba(local_test,axis=1))[:,1]\n",
    "        \n",
    "del local_train, local_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['is_churn'] = Y_preds.clip(0.+1e-15, 1-1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['msno','is_churn']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
